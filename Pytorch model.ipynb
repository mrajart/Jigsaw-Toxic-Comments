{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "\n",
    "#Text Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b6e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda5ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaa09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2021,\n",
    "          \"epochs\": 10,\n",
    "          \"model_name\": \"unitary/toxic-bert\",\n",
    "          \"train_batch_size\": 28,\n",
    "          \"valid_batch_size\": 56,\n",
    "          \"max_length\": 100,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"epsilon\" : 1e-6,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 5e-7,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-5,\n",
    "          \"n_fold\": 1,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 1,\n",
    "          \"margin\": 0.5,\n",
    "          \"patience\": 4,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c91f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1933ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banning guns and explosives doesn t make a sta...</td>\n",
       "      <td>Banning guns and explosives doesn t make a sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I m saying it hasn t been researched and yet t...</td>\n",
       "      <td>I m saying it hasn t been researched and yet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fuck did I just read</td>\n",
       "      <td>what what the fuck did i just read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It s almost as if these leave voting money gru...</td>\n",
       "      <td>Leading Britain off a cliff and cheating their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bulgaria Croatia Czech Republic Denmark Hungar...</td>\n",
       "      <td>Bulgaria Croatia Czech Republic Denmark Hungar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          more_toxic  \\\n",
       "0  Banning guns and explosives doesn t make a sta...   \n",
       "1  I m saying it hasn t been researched and yet t...   \n",
       "2                           The fuck did I just read   \n",
       "3  It s almost as if these leave voting money gru...   \n",
       "4  Bulgaria Croatia Czech Republic Denmark Hungar...   \n",
       "\n",
       "                                          less_toxic  \n",
       "0  Banning guns and explosives doesn t make a sta...  \n",
       "1  I m saying it hasn t been researched and yet t...  \n",
       "2                 what what the fuck did i just read  \n",
       "3  Leading Britain off a cliff and cheating their...  \n",
       "4  Bulgaria Croatia Czech Republic Denmark Hungar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ead45fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(\"input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb18e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class UnionFind():\\n    def __init__(self, n):\\n        self.n = n\\n        self.parents = [-1] * n\\n\\n    def find(self, x):\\n        if self.parents[x] < 0:\\n            return x\\n        else:\\n            self.parents[x] = self.find(self.parents[x])\\n            return self.parents[x]\\n\\n    def union(self, x, y):\\n        x = self.find(x)\\n        y = self.find(y)\\n        if x == y:\\n            return\\n        if self.parents[x] > self.parents[y]:\\n            x, y = y, x\\n        self.parents[x] += self.parents[y]\\n        self.parents[y] = x\\n\\n\\ndef get_group_unionfind(train: pd.DataFrame):\\n    less_unique_text = train['less_toxic'].unique()\\n    more_unique_text = train['more_toxic'].unique()\\n    unique_text = np.hstack([less_unique_text, more_unique_text])\\n    unique_text = np.unique(unique_text).tolist()    \\n    text2num = {text: i for i, text in enumerate(unique_text)}\\n    num2text = {num: text for text, num in text2num.items()}\\n    train['num_less_toxic'] = train['less_toxic'].map(text2num)\\n    train['num_more_toxic'] = train['more_toxic'].map(text2num)\\n\\n    uf = UnionFind(len(unique_text))\\n    for seq1, seq2 in train[['num_less_toxic', 'num_more_toxic']].to_numpy():\\n        uf.union(seq1, seq2)\\n\\n    text2group = {num2text[i]: uf.find(i) for i in range(len(unique_text))}\\n    train['group'] = train['less_toxic'].map(text2group)\\n    train = train.drop(columns=['num_less_toxic', 'num_more_toxic'])\\n    return train\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class UnionFind():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.parents = [-1] * n\n",
    "\n",
    "    def find(self, x):\n",
    "        if self.parents[x] < 0:\n",
    "            return x\n",
    "        else:\n",
    "            self.parents[x] = self.find(self.parents[x])\n",
    "            return self.parents[x]\n",
    "\n",
    "    def union(self, x, y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        if self.parents[x] > self.parents[y]:\n",
    "            x, y = y, x\n",
    "        self.parents[x] += self.parents[y]\n",
    "        self.parents[y] = x\n",
    "\n",
    "\n",
    "def get_group_unionfind(train: pd.DataFrame):\n",
    "    less_unique_text = train['less_toxic'].unique()\n",
    "    more_unique_text = train['more_toxic'].unique()\n",
    "    unique_text = np.hstack([less_unique_text, more_unique_text])\n",
    "    unique_text = np.unique(unique_text).tolist()    \n",
    "    text2num = {text: i for i, text in enumerate(unique_text)}\n",
    "    num2text = {num: text for text, num in text2num.items()}\n",
    "    train['num_less_toxic'] = train['less_toxic'].map(text2num)\n",
    "    train['num_more_toxic'] = train['more_toxic'].map(text2num)\n",
    "\n",
    "    uf = UnionFind(len(unique_text))\n",
    "    for seq1, seq2 in train[['num_less_toxic', 'num_more_toxic']].to_numpy():\n",
    "        uf.union(seq1, seq2)\n",
    "\n",
    "    text2group = {num2text[i]: uf.find(i) for i in range(len(unique_text))}\n",
    "    train['group'] = train['less_toxic'].map(text2group)\n",
    "    train = train.drop(columns=['num_less_toxic', 'num_more_toxic'])\n",
    "    return train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f7d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61cbfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.less_toxic = df_train.less_toxic.apply(text_cleaning)\n",
    "df_train.more_toxic = df_train.more_toxic.apply(text_cleaning)\n",
    "df_valid.less_toxic = df_valid.less_toxic.apply(text_cleaning)\n",
    "df_valid.more_toxic = df_valid.more_toxic.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad97aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1, random_state=CONFIG['seed'])\n",
    "df_valid = df_valid.sample(frac=1, random_state=CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618f819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_group_unionfind(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb3c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'group_kfold = GroupKFold(n_splits=5)\\nfor fold, (trn_idx, val_idx) in enumerate(group_kfold.split(df, df, df[\\'group\\'])): \\n    df.loc[val_idx , \"kfold\"] = fold\\n\\ndf[\"kfold\"] = df[\"kfold\"].astype(int)\\ndf.to_csv(\\'train_noleak.csv\\', index=False)\\ndf.head()'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''group_kfold = GroupKFold(n_splits=5)\n",
    "for fold, (trn_idx, val_idx) in enumerate(group_kfold.split(df, df, df['group'])): \n",
    "    df.loc[val_idx , \"kfold\"] = fold\n",
    "\n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.to_csv('train_noleak.csv', index=False)\n",
    "df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba9ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.more_toxic = df['more_toxic'].values\n",
    "        self.less_toxic = df['less_toxic'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        more_toxic = self.more_toxic[index]\n",
    "        less_toxic = self.less_toxic[index]\n",
    "        inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                                more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                                less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "        \n",
    "        more_toxic_ids = inputs_more_toxic['input_ids']\n",
    "        more_toxic_mask = inputs_more_toxic['attention_mask']\n",
    "        \n",
    "        less_toxic_ids = inputs_less_toxic['input_ids']\n",
    "        less_toxic_mask = inputs_less_toxic['attention_mask']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.int),\n",
    "            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.int),\n",
    "            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.int),\n",
    "            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.int),\n",
    "            'target': torch.tensor(target, dtype=torch.int)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22d229d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                             output_hidden_states=False)\n",
    "        out = self.drop(out[1])\n",
    "        out = out[1]\n",
    "        outputs = self.fc(out)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4ff9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25cf6761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class SoftLoss(nn.Module):\\n    def __init__(self):\\n        super(SoftLoss, self).__init__()\\n        \\n    def forward(self, pred1, pred2, target, margin = 0.5):\\n        #return torch.log(1.0 + torch.exp(pred1 - pred2 + margin))\\n        return nn.Softplus()(pred1 - pred2 + margin)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class SoftLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoftLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred1, pred2, target, margin = 0.5):\n",
    "        #return torch.log(1.0 + torch.exp(pred1 - pred2 + margin))\n",
    "        return nn.Softplus()(pred1 - pred2 + margin)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3dcddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def criterion(outputs1, outputs2, targets):\\n    return SoftLoss()(outputs1, outputs2, targets, CONFIG['margin'])\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def criterion(outputs1, outputs2, targets):\n",
    "    return SoftLoss()(outputs1, outputs2, targets, CONFIG['margin'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2455f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_more_toxic, y_less_toxic): \n",
    "    correct = torch.sum(torch.where(y_more_toxic>y_less_toxic, 1, 0))\n",
    "    wrong = torch.sum(torch.where(y_more_toxic<=y_less_toxic, 1, 0))\n",
    "    acc = correct / (correct + wrong)\n",
    "    return acc.view(-1).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a4e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #Automatic Mixed Precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    #------------------\n",
    "    \n",
    "    score_batch = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "            \n",
    "        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.int)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.int)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.int)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.int)\n",
    "\n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        #Automatic Mixed Precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "        #------------------\n",
    "            more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "            less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "            loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "            loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "            score_batch.append(accuracy(more_toxic_outputs, less_toxic_outputs))\n",
    "        \n",
    "        #Automatic Mixed Precision\n",
    "        scaler.scale(loss).backward()\n",
    "        #------------------\n",
    "\n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "                \n",
    "            #optimizer.step()\n",
    "            \n",
    "            #Automatic Mixed Precision\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            #------------------\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    " \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        epoch_score = np.mean(score_batch)\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                            LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    return epoch_loss, epoch_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "febba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    score_batch = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.int)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.int)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.int)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.int)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "        score_batch.append(accuracy(more_toxic_outputs, less_toxic_outputs))\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        epoch_score = np.mean(score_batch)\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    return epoch_loss, epoch_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ae106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_score = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_score = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train Score'].append(train_epoch_score)\n",
    "        history['Valid Score'].append(val_epoch_score)\n",
    "        \n",
    "        print(f\"{b_}Train score {train_epoch_score}\")\n",
    "        print(f\"{b_}Valid score {val_epoch_score}\")\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            history[\"Best Loss\"].append(best_epoch_loss)\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= CONFIG[\"patience\"]:\n",
    "                print('Early stopping!' )\n",
    "                print()\n",
    "                break\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "454d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    #df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    #df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = JigsawDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a30576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99525e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 2147/2147 [10:16<00:00,  3.48it/s, Epoch=1, LR=8.11e-6, Train_Loss=0.437\n",
      "100%|██| 538/538 [02:59<00:00,  3.00it/s, Epoch=1, LR=8.11e-6, Valid_Loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrain score 0.5961807370185852\n",
      "\u001b[34mValid score 0.6505576372146606\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.45401408647448005)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 2147/2147 [10:17<00:00,  3.48it/s, Epoch=2, LR=3.95e-6, Train_Loss=0.426\n",
      "100%|██| 538/538 [02:57<00:00,  3.04it/s, Epoch=2, LR=3.95e-6, Valid_Loss=0.471]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrain score 0.6064275503158569\n",
      "\u001b[34mValid score 0.6617100238800049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█| 2147/2147 [10:15<00:00,  3.49it/s, Epoch=3, LR=8.23e-7, Train_Loss=0.391\n",
      "100%|██| 538/538 [02:57<00:00,  3.03it/s, Epoch=3, LR=8.23e-7, Valid_Loss=0.486]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrain score 0.6478807926177979\n",
      "\u001b[34mValid score 0.6505576372146606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█| 2147/2147 [10:15<00:00,  3.49it/s, Epoch=4, LR=1.21e-6, Train_Loss=0.395\n",
      "100%|██| 538/538 [02:57<00:00,  3.03it/s, Epoch=4, LR=1.21e-6, Valid_Loss=0.472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrain score 0.6422915458679199\n",
      "\u001b[34mValid score 0.6375464797019958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█| 2147/2147 [10:21<00:00,  3.46it/s, Epoch=5, LR=4.8e-6, Train_Loss=0.374]\n",
      "100%|███| 538/538 [02:58<00:00,  3.02it/s, Epoch=5, LR=4.8e-6, Valid_Loss=0.502]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrain score 0.6627852916717529\n",
      "\u001b[34mValid score 0.6486988663673401\n",
      "Early stopping!\n",
      "\n",
      "Training complete in 1h 6m 17s\n",
      "Best Loss: 0.4540\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = JigsawModel(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], eps=CONFIG['epsilon'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
