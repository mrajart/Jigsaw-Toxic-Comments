{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "\n",
    "#Text Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03235472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\r\n",
      "Cuda compilation tools, release 11.3, V11.3.109\r\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b6e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74875f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaa09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2021,\n",
    "          \"epochs\": 4,\n",
    "          \"model_name\": \"GroNLP/hateBERT\",\n",
    "          \"train_batch_size\": 28,\n",
    "          \"valid_batch_size\": 56,\n",
    "          \"max_length\": 100,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"epsilon\" : 1e-7,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-5,\n",
    "          \"n_fold\": 1,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 1,\n",
    "          \"margin\": 0.5,\n",
    "          \"patience\": 2,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c91f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1933ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>offensiveness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; The difference in average earnings between m...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The myth is that the \"gap\" is entirely based o...</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The assertion is that women get paid less for ...</td>\n",
       "      <td>-0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You said in the OP that's not what they're mea...</td>\n",
       "      <td>-0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;Men and women are not payed less for the same...</td>\n",
       "      <td>-0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  offensiveness_score\n",
       "0  > The difference in average earnings between m...               -0.083\n",
       "1  The myth is that the \"gap\" is entirely based o...               -0.022\n",
       "2  The assertion is that women get paid less for ...               -0.146\n",
       "3  You said in the OP that's not what they're mea...               -0.083\n",
       "4  >Men and women are not payed less for the same...               -0.042"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a8983b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(\"input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f7d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fed5ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.txt=df_train.txt.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61cbfb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.txt = df_train.txt.apply(text_cleaning)\n",
    "df_valid.less_toxic = df_valid.less_toxic.apply(text_cleaning)\n",
    "df_valid.more_toxic = df_valid.more_toxic.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb3c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'group_kfold = GroupKFold(n_splits=5)\\nfor fold, (trn_idx, val_idx) in enumerate(group_kfold.split(df, df, df[\\'group\\'])): \\n    df.loc[val_idx , \"kfold\"] = fold\\n\\ndf[\"kfold\"] = df[\"kfold\"].astype(int)\\ndf.to_csv(\\'train_noleak.csv\\', index=False)\\ndf.head()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''group_kfold = GroupKFold(n_splits=5)\n",
    "for fold, (trn_idx, val_idx) in enumerate(group_kfold.split(df, df, df['group'])): \n",
    "    df.loc[val_idx , \"kfold\"] = fold\n",
    "\n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.to_csv('train_noleak.csv', index=False)\n",
    "df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba9ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDatasetTrain(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.txt = df['txt'].values\n",
    "        self.target = df['offensiveness_score'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        txt = self.txt[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                                txt,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = self.target\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.int),\n",
    "            'mask': torch.tensor(mask, dtype=torch.int),\n",
    "            'target': torch.tensor(target, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210c0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDatasetValid(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.more_toxic = df['more_toxic'].values\n",
    "        self.less_toxic = df['less_toxic'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        more_toxic = self.more_toxic[index]\n",
    "        less_toxic = self.less_toxic[index]\n",
    "        inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                                more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                                less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "        \n",
    "        more_toxic_ids = inputs_more_toxic['input_ids']\n",
    "        more_toxic_mask = inputs_more_toxic['attention_mask']\n",
    "        \n",
    "        less_toxic_ids = inputs_less_toxic['input_ids']\n",
    "        less_toxic_mask = inputs_less_toxic['attention_mask']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.int),\n",
    "            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.int),\n",
    "            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.int),\n",
    "            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.int),\n",
    "            'target': torch.tensor(target, dtype=torch.int)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22d229d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                             output_hidden_states=False)\n",
    "        out = self.drop(out[1])\n",
    "        outputs = self.fc(out)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4ff9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_validation(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac1395a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion_train(outputs, targets):\n",
    "    return nn.MSELoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aea1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_more_toxic, y_less_toxic): \n",
    "    correct = torch.sum(torch.where(y_more_toxic>y_less_toxic, 1, 0))\n",
    "    wrong = torch.sum(torch.where(y_more_toxic<=y_less_toxic, 1, 0))\n",
    "    acc = correct / (correct + wrong)\n",
    "    return acc.view(-1).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a4e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #Automatic Mixed Precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    #------------------\n",
    "    \n",
    "    score_batch = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "            \n",
    "        \n",
    "        ids = data['ids'].to(device, dtype = torch.int)\n",
    "        mask = data['mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        #Automatic Mixed Precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "        #------------------\n",
    "            outputs = model(ids, mask)\n",
    "            loss = criterion_train(outputs, targets)\n",
    "            loss = loss / CONFIG['n_accumulate']\n",
    "        \n",
    "        #Automatic Mixed Precision\n",
    "        scaler.scale(loss).backward()\n",
    "        #------------------\n",
    "\n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "                \n",
    "            #optimizer.step()\n",
    "            \n",
    "            #Automatic Mixed Precision\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            #------------------\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    " \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                            LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "febba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    score_batch = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.int)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.int)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.int)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.int)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        loss = criterion_validation(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "        score_batch.append(accuracy(more_toxic_outputs, less_toxic_outputs))\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        epoch_score = np.mean(score_batch)\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    return epoch_loss, epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5ae106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_score = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Valid Score'].append(val_epoch_score)\n",
    "        \n",
    "        print(f\"{b_}Valid score {val_epoch_score}\")\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            history[\"Best Loss\"].append(best_epoch_loss)\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= CONFIG[\"patience\"]:\n",
    "                print('Early stopping!' )\n",
    "                print()\n",
    "                break\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "454d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    #df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    #df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = JigsawDatasetTrain(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = JigsawDatasetValid(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a30576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99525e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 8187/8187 [25:06<00:00,  5.43it/s, Epoch=1, LR=7.24e-6, Train_Loss=0.052\n",
      "100%|████| 538/538 [03:00<00:00,  2.98it/s, Epoch=1, LR=7.24e-6, Valid_Loss=0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValid score 0.5555223822593689\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.49987811226681345)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|▉| 7938/8187 [23:59<00:44,  5.59it/s, Epoch=2, LR=8.66e-6, Train_Loss=0.051"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = JigsawModel(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], eps=CONFIG['epsilon'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
