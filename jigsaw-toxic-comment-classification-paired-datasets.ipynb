{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ade655",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-13T18:33:37.976724Z",
     "iopub.status.busy": "2021-12-13T18:33:37.975512Z",
     "iopub.status.idle": "2021-12-13T18:33:39.104178Z",
     "shell.execute_reply": "2021-12-13T18:33:39.103484Z",
     "shell.execute_reply.started": "2021-12-13T13:06:02.524525Z"
    },
    "papermill": {
     "duration": 1.140148,
     "end_time": "2021-12-13T18:33:39.104372",
     "exception": false,
     "start_time": "2021-12-13T18:33:37.964224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import combinations\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "#Text Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee64076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81cbc4",
   "metadata": {
    "papermill": {
     "duration": 0.004814,
     "end_time": "2021-12-13T18:33:39.133178",
     "exception": false,
     "start_time": "2021-12-13T18:33:39.128364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data\n",
    "\n",
    "Create all pairs for the Ruddit dataset - we preserve the original scores, so that a difference (pointing which one is more toxic) can be adjusted at modeling time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fd2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9029a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_dataset_as(task=\"binary\", regression_weights=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        task: ['binary', 'regression']\n",
    "        regression_weights: dictionary {label => weights} for each label or None, if task=='regression'\n",
    "        \n",
    "    \"\"\"\n",
    "    assert task in ['binary', 'regression']\n",
    "    \n",
    "    df = pd.read_csv('input/jigsaw-toxic-comment-classification-challenge/classification-dataset.csv')\n",
    "\n",
    "    \n",
    "    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    if task == 'binary':    \n",
    "        df['y'] = (df[labels].sum(axis=1) > 0).astype(int)\n",
    "        df = df.drop(labels, axis=1)\n",
    "    elif task == 'regression':\n",
    "        if regression_weights is None:\n",
    "            df['y'] = df[labels].sum(axis=1)\n",
    "        else:\n",
    "            weighed_columns = [regression_weights.get(l, 1) * df[l] for l in labels]\n",
    "            df['y'] = pd.concat(weighed_columns, axis=1).sum(axis=1)\n",
    "        df = df.drop(labels, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af75d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_classification_dataset_as('regression', regression_weights={'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n",
    "            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a2ab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text    y\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...  0.0\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...  0.0\n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...  0.0\n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...  0.0\n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3787ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee5f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment_text = df.comment_text.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8a90fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97acc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"paraphrase-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c11741",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef00f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152d73fba6ab467191cd6feb189dc4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.35 GiB (GPU 0; 7.79 GiB total capacity; 4.69 GiB already allocated; 758.62 MiB free; 4.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_67479/633538284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparaphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparaphrase_mining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_chunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_chunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36mparaphrase_mining\u001b[0;34m(model, sentences, show_progress_bar, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparaphrase_mining_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36mparaphrase_mining_embeddings\u001b[0;34m(embeddings, query_chunk_size, corpus_chunk_size, max_pairs, top_k, score_function)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcorpus_start_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery_start_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_start_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mquery_start_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mquery_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus_start_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcorpus_start_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcorpus_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mscores_top_k_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_top_k_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0ma_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mb_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.35 GiB (GPU 0; 7.79 GiB total capacity; 4.69 GiB already allocated; 758.62 MiB free; 4.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "paraphrases = util.paraphrase_mining(model, sentences, show_progress_bar = True, query_chunk_size = 10000, corpus_chunk_size=90000, max_pairs = 150000, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paraphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = pd.DataFrame(paraphrases, columns=['score', 'toxic1', 'toxic2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14840411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be52377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair['toxic1'] = df_pair.apply(lambda row: sentences[row['toxic1']] , axis=1)\n",
    "df_pair['toxic2'] = df_pair.apply(lambda row: sentences[row['toxic2']] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = df_pair[df_pair.score < 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ed745",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df.txt = df.txt.apply(str)\n",
    "df_pair.txt = df_pair.txt.apply(str)\n",
    "df_pair.toxic2 = df_pair.toxic2.apply(str)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8959b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.join(df.set_index('comment_text'), on=['toxic1'], how='left').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = df_pair.join(df.set_index('comment_text'), on=['toxic1'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.drop(['id'], axis=1, inplace=True)\n",
    "df_pair.rename(columns={\"y\": \"toxic_score1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13575ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair = df_pair.join(df.set_index('comment_text'), on=['toxic2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1fe3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.drop(['id'], axis=1, inplace=True)\n",
    "df_pair.rename(columns={\"y\": \"toxic_score2\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb137e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c40863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.drop(['score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dd6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair['toxic1'], df_pair['toxic2'], df_pair['toxic_score1'], df_pair['toxic_score2']=np.where(df_pair['toxic_score1'] > df_pair['toxic_score2'],(df_pair['toxic1'], df_pair['toxic2'], df_pair['toxic_score1'], df_pair['toxic_score2']),(df_pair['toxic2'],df_pair['toxic1'], df_pair['toxic_score2'], df_pair['toxic_score1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301978f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da2a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pair.drop(['toxic_score1', 'toxic_score2'], axis=1, inplace=True)\n",
    "df_pair.rename(columns={\"toxic1\": \"more_toxic\", \"toxic2\": \"less_toxic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump to file\n",
    "df_pair.to_csv('jigsaw-toxic-commenr-classification-pair.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 375.558485,
   "end_time": "2021-12-13T18:39:43.177235",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-13T18:33:27.618750",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
