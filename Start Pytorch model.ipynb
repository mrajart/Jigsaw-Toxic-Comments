{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9428dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b43c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03235472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\r\n",
      "Built on Mon_May__3_19:15:13_PDT_2021\r\n",
      "Cuda compilation tools, release 11.3, V11.3.109\r\n",
      "Build cuda_11.3.r11.3/compiler.29920130_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b6e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda5ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36ca6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class Config:\\n    \\n    model_name = \\'../input/roberta-base\\'\\n        \\n    learning_rate = 1e-4\\n    epochs = 1\\n    train_bs =32\\n    valid_bs = 64\\n    test_bs = 128\\n        \\n    seed = 2021\\n    max_length = 128\\n    min_lr = 1e-7\\n    scheduler = \\'CosineAnnealingLR\\' # 学习率衰减策略\\n    T_max  = 500\\n    weight_decay = 1e-6 # 权重衰减 L2正则化 减少过拟合\\n    max_grad_norm = 1.0 # 用于控制梯度膨胀，如果梯度向量的L2模超过max_grad_norm，则等比例缩小\\n    num_classes = 1\\n    margin = 0.5\\n    n_fold = 5\\n    n_accululate = 1\\n    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n    \\n    hidden_size =768\\n    num_hidden_layers = 24\\n    \\n    dropout = 0.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class Config:\n",
    "    \n",
    "    model_name = '../input/roberta-base'\n",
    "        \n",
    "    learning_rate = 1e-4\n",
    "    epochs = 1\n",
    "    train_bs =32\n",
    "    valid_bs = 64\n",
    "    test_bs = 128\n",
    "        \n",
    "    seed = 2021\n",
    "    max_length = 128\n",
    "    min_lr = 1e-7\n",
    "    scheduler = 'CosineAnnealingLR' # 学习率衰减策略\n",
    "    T_max  = 500\n",
    "    weight_decay = 1e-6 # 权重衰减 L2正则化 减少过拟合\n",
    "    max_grad_norm = 1.0 # 用于控制梯度膨胀，如果梯度向量的L2模超过max_grad_norm，则等比例缩小\n",
    "    num_classes = 1\n",
    "    margin = 0.5\n",
    "    n_fold = 5\n",
    "    n_accululate = 1\n",
    "    device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    hidden_size =768\n",
    "    num_hidden_layers = 24\n",
    "    \n",
    "    dropout = 0.2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baaa09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 2021,\n",
    "          \"epochs\": 3,\n",
    "          \"model_name\": \"GroNLP/hateBERT\",\n",
    "          \"train_batch_size\": 28,\n",
    "          \"valid_batch_size\": 56,\n",
    "          \"max_length\": 100,\n",
    "          \"learning_rate\": 5e-5,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 5,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 1,\n",
    "          \"margin\": 0.5,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c91f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1933ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"input/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0491d771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  kfold  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...      4  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...      0  \n",
       "2  \"Atom you don't believe actual photos of mastu...      0  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...      2  \n",
       "4           hey \\n\\nway to support nazis, you racist      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.worker)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba9ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.more_toxic = df['more_toxic'].values\n",
    "        self.less_toxic = df['less_toxic'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        more_toxic = self.more_toxic[index]\n",
    "        less_toxic = self.less_toxic[index]\n",
    "        inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                                more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                                less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "        \n",
    "        more_toxic_ids = inputs_more_toxic['input_ids']\n",
    "        more_toxic_mask = inputs_more_toxic['attention_mask']\n",
    "        \n",
    "        less_toxic_ids = inputs_less_toxic['input_ids']\n",
    "        less_toxic_mask = inputs_less_toxic['attention_mask']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.int),\n",
    "            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.int),\n",
    "            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.int),\n",
    "            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.int),\n",
    "            'target': torch.tensor(target, dtype=torch.int)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d229d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(768, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                             output_hidden_states=False)\n",
    "        out = self.drop(out[1])\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4ff9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a4e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #Automatic Mixed Precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    #------------------\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "            \n",
    "        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.int)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.int)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.int)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.int)\n",
    "\n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        #Automatic Mixed Precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "        #------------------\n",
    "            more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "            less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "            loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "            loss = loss / CONFIG['n_accumulate']\n",
    "        \n",
    "        #Automatic Mixed Precision\n",
    "        scaler.scale(loss).backward()\n",
    "        #------------------\n",
    "\n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "                \n",
    "            #optimizer.step()\n",
    "            \n",
    "            #Automatic Mixed Precision\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            #------------------\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    " \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                            LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "febba625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.int)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.int)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.int)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.int)\n",
    "        targets = data['target'].to(device, dtype=torch.int)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n",
    "        \n",
    "        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5ae106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        \n",
    "\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            #run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "454d1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = JigsawDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a30576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99525e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:09<00:00,  3.45it/s, Epoch=1, LR=4.11e-5, Train_Loss=0.358]\n",
      "100%|██| 108/108 [00:36<00:00,  2.97it/s, Epoch=1, LR=4.11e-5, Valid_Loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.3493074211754382)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:12<00:00,  3.41it/s, Epoch=2, LR=2.09e-5, Train_Loss=0.334]\n",
      "100%|██| 108/108 [00:36<00:00,  3.00it/s, Epoch=2, LR=2.09e-5, Valid_Loss=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.3493074211754382 ---> 0.3369933101613036)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:13<00:00,  3.39it/s, Epoch=3, LR=4.03e-6, Train_Loss=0.307]\n",
      "100%|██| 108/108 [00:36<00:00,  2.97it/s, Epoch=3, LR=4.03e-6, Valid_Loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0h 14m 26s\n",
      "Best Loss: 0.3370\n",
      "\n",
      "\u001b[33m====== Fold: 1 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:14<00:00,  3.37it/s, Epoch=1, LR=4.11e-5, Train_Loss=0.357]\n",
      "100%|██| 108/108 [00:36<00:00,  2.98it/s, Epoch=1, LR=4.11e-5, Valid_Loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.3569630403943887)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:11<00:00,  3.42it/s, Epoch=2, LR=2.09e-5, Train_Loss=0.324]\n",
      "100%|██| 108/108 [00:36<00:00,  2.99it/s, Epoch=2, LR=2.09e-5, Valid_Loss=0.341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.3569630403943887 ---> 0.341101918900302)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:11<00:00,  3.42it/s, Epoch=3, LR=4.03e-6, Train_Loss=0.304]\n",
      "100%|██| 108/108 [00:39<00:00,  2.72it/s, Epoch=3, LR=4.03e-6, Valid_Loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0h 14m 32s\n",
      "Best Loss: 0.3411\n",
      "\n",
      "\u001b[33m====== Fold: 2 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:10<00:00,  3.44it/s, Epoch=1, LR=4.11e-5, Train_Loss=0.356]\n",
      "100%|██| 108/108 [00:36<00:00,  2.99it/s, Epoch=1, LR=4.11e-5, Valid_Loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.34800329427313703)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:07<00:00,  3.48it/s, Epoch=2, LR=2.09e-5, Train_Loss=0.327]\n",
      "100%|███| 108/108 [00:35<00:00,  3.02it/s, Epoch=2, LR=2.09e-5, Valid_Loss=0.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.34800329427313703 ---> 0.3397659766776979)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████| 860/860 [04:06<00:00,  3.50it/s, Epoch=3, LR=4.03e-6, Train_Loss=0.3]\n",
      "100%|██| 108/108 [00:35<00:00,  3.02it/s, Epoch=3, LR=4.03e-6, Valid_Loss=0.347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0h 14m 13s\n",
      "Best Loss: 0.3398\n",
      "\n",
      "\u001b[33m====== Fold: 3 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:09<00:00,  3.45it/s, Epoch=1, LR=4.11e-5, Train_Loss=0.357]\n",
      "100%|██| 108/108 [00:36<00:00,  2.99it/s, Epoch=1, LR=4.11e-5, Valid_Loss=0.343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.34261022992475426)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:09<00:00,  3.44it/s, Epoch=2, LR=2.09e-5, Train_Loss=0.342]\n",
      "100%|██| 108/108 [00:36<00:00,  2.99it/s, Epoch=2, LR=2.09e-5, Valid_Loss=0.336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.34261022992475426 ---> 0.33641061873812944)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 860/860 [04:08<00:00,  3.45it/s, Epoch=3, LR=4.03e-6, Train_Loss=0.32]\n",
      "100%|██| 108/108 [00:36<00:00,  2.99it/s, Epoch=3, LR=4.03e-6, Valid_Loss=0.335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.33641061873812944 ---> 0.33464388907935766)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "Training complete in 0h 14m 19s\n",
      "Best Loss: 0.3346\n",
      "\n",
      "\u001b[33m====== Fold: 4 ======\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██| 860/860 [04:11<00:00,  3.42it/s, Epoch=1, LR=4.11e-5, Train_Loss=0.357]\n",
      "100%|██| 108/108 [00:36<00:00,  2.96it/s, Epoch=1, LR=4.11e-5, Valid_Loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (inf ---> 0.34616987957369943)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 860/860 [04:10<00:00,  3.43it/s, Epoch=2, LR=2.09e-5, Train_Loss=0.33]\n",
      "100%|██| 108/108 [00:36<00:00,  2.96it/s, Epoch=2, LR=2.09e-5, Valid_Loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mValidation Loss Improved (0.34616987957369943 ---> 0.3387380821565084)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███| 860/860 [04:10<00:00,  3.44it/s, Epoch=3, LR=4.03e-6, Train_Loss=0.31]\n",
      "100%|██| 108/108 [00:36<00:00,  2.97it/s, Epoch=3, LR=4.03e-6, Valid_Loss=0.342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0h 14m 24s\n",
      "Best Loss: 0.3387\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = JigsawModel(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
