{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl","metadata":{"id":"mylVkVc9Fvqq","outputId":"f92becd7-0524-4fd4-fd22-5ff1f741de81","execution":{"iopub.status.busy":"2022-02-07T08:12:18.935125Z","iopub.execute_input":"2022-02-07T08:12:18.935586Z","iopub.status.idle":"2022-02-07T08:13:45.813942Z","shell.execute_reply.started":"2022-02-07T08:12:18.935449Z","shell.execute_reply":"2022-02-07T08:13:45.812692Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch-xla==1.9\n  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)\n\u001b[K     |████████████████████████████████| 149.9 MB 26 kB/s s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cloud-tpu-client==0.10 in /opt/conda/lib/python3.7/site-packages (0.10)\nCollecting torch==1.9.0\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 1.1 kB/s  eta 0:00:017     |█████████████████████           | 548.2 MB 93.9 MB/s eta 0:00:04\n\u001b[?25hRequirement already satisfied: google-api-python-client==1.8.0 in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client==0.10) (1.8.0)\nRequirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client==0.10) (4.1.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0) (3.7.4.3)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.1)\nRequirement already satisfied: google-auth>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.0)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.19.1)\nRequirement already satisfied: six<2dev,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.53.0)\nRequirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (57.4.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.25.1)\nRequirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.18.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.2)\nRequirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.4.7)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.26.6)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\nInstalling collected packages: torch-xla, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 1.7.1+cpu\n    Uninstalling torch-1.7.1+cpu:\n      Successfully uninstalled torch-1.7.1+cpu\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchvision 0.8.2+cpu requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\ntorchtext 0.8.1 requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\ntorchaudio 0.7.2 requires torch==1.7.1, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0 torch-xla-1.9\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport copy\nimport time\nimport random\nimport string\nimport os\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\n# Utils\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n\n#Text Cleaning\nfrom bs4 import BeautifulSoup\nimport re \n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel, AdamW\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","metadata":{"id":"3f9428dd","execution":{"iopub.status.busy":"2022-02-07T08:13:45.818607Z","iopub.execute_input":"2022-02-07T08:13:45.819364Z","iopub.status.idle":"2022-02-07T08:13:54.901680Z","shell.execute_reply.started":"2022-02-07T08:13:45.819314Z","shell.execute_reply":"2022-02-07T08:13:54.900436Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2022-02-07 08:13:50.356688: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-02-07 08:13:50.357482: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"# imports the torch_xla package\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.serialization as xser\n\n'''import torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.test.test_utils as test_utils'''","metadata":{"id":"jgoJaFvnFz0g","outputId":"9d55b6df-944a-441f-f028-270435fb6037","execution":{"iopub.status.busy":"2022-02-07T08:13:54.903390Z","iopub.execute_input":"2022-02-07T08:13:54.903720Z","iopub.status.idle":"2022-02-07T08:14:37.138065Z","shell.execute_reply.started":"2022-02-07T08:13:54.903683Z","shell.execute_reply":"2022-02-07T08:14:37.137124Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'import torch_xla\\nimport torch_xla.debug.metrics as met\\nimport torch_xla.distributed.parallel_loader as pl\\nimport torch_xla.utils.utils as xu\\nimport torch_xla.core.xla_model as xm\\nimport torch_xla.distributed.xla_multiprocessing as xmp\\nimport torch_xla.test.test_utils as test_utils'"},"metadata":{}}]},{"cell_type":"code","source":"os.environ['XLA_USE_BF16']=\"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'","metadata":{"id":"0Ly1mGwcZmyJ","execution":{"iopub.status.busy":"2022-02-07T08:14:37.139998Z","iopub.execute_input":"2022-02-07T08:14:37.140409Z","iopub.status.idle":"2022-02-07T08:14:37.145346Z","shell.execute_reply.started":"2022-02-07T08:14:37.140373Z","shell.execute_reply":"2022-02-07T08:14:37.144423Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\"seed\": 2021,\n          \"epochs\": 10,\n          \"model_name\": \"unitary/unbiased-toxic-roberta\",\n          \"train_batch_size\": 8,\n          \"valid_batch_size\": 16,\n          \"max_length\": 512,\n          \"learning_rate\": 1e-5,\n          \"epsilon\" : 1e-6,\n          \"scheduler\": 'CosineAnnealingLR',\n          \"min_lr\": 1e-6,\n          \"T_max\": 500,\n          \"weight_decay\": 1e-5,\n          \"n_fold\": 1,\n          \"n_accumulate\": 1,\n          \"num_classes\": 1,\n          \"margin\": 0.5,\n          \"patience\": 4\n          }\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","metadata":{"id":"baaa09c5","execution":{"iopub.status.busy":"2022-02-07T08:14:37.148016Z","iopub.execute_input":"2022-02-07T08:14:37.149166Z","iopub.status.idle":"2022-02-07T08:14:39.953904Z","shell.execute_reply.started":"2022-02-07T08:14:37.149120Z","shell.execute_reply":"2022-02-07T08:14:39.952873Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183dcd340a5d47fab46e120e20cc7e0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bbb7f56b1ed4c159fd19eedd4267132"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b56f58a14348b8b52a327e27028222"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13536b0ee91349d2a2f171c987e7518f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/997 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09c91df703ae4f35871bc94b6ca498b2"}},"metadata":{}}]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"id":"3c91f71b","execution":{"iopub.status.busy":"2022-02-07T08:14:39.955228Z","iopub.execute_input":"2022-02-07T08:14:39.955476Z","iopub.status.idle":"2022-02-07T08:14:39.965536Z","shell.execute_reply.started":"2022-02-07T08:14:39.955446Z","shell.execute_reply":"2022-02-07T08:14:39.964434Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/train-jigsaw-rate/train.csv')\ndf_train.head()","metadata":{"id":"a1933ddc","outputId":"028b20a1-6754-4757-e46b-2e441eb0e995","execution":{"iopub.status.busy":"2022-02-07T08:14:39.966980Z","iopub.execute_input":"2022-02-07T08:14:39.967320Z","iopub.status.idle":"2022-02-07T08:14:40.717999Z","shell.execute_reply.started":"2022-02-07T08:14:39.967216Z","shell.execute_reply":"2022-02-07T08:14:40.716999Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                          more_toxic  \\\n0  Banning guns and explosives doesn t make a sta...   \n1  I m saying it hasn t been researched and yet t...   \n2                           The fuck did I just read   \n3  It s almost as if these leave voting money gru...   \n4  Bulgaria Croatia Czech Republic Denmark Hungar...   \n\n                                          less_toxic  \n0  Banning guns and explosives doesn t make a sta...  \n1  I m saying it hasn t been researched and yet t...  \n2                 what what the fuck did i just read  \n3  Leading Britain off a cliff and cheating their...  \n4  Bulgaria Croatia Czech Republic Denmark Hungar...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>more_toxic</th>\n      <th>less_toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Banning guns and explosives doesn t make a sta...</td>\n      <td>Banning guns and explosives doesn t make a sta...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I m saying it hasn t been researched and yet t...</td>\n      <td>I m saying it hasn t been researched and yet t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The fuck did I just read</td>\n      <td>what what the fuck did i just read</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It s almost as if these leave voting money gru...</td>\n      <td>Leading Britain off a cliff and cheating their...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bulgaria Croatia Czech Republic Denmark Hungar...</td>\n      <td>Bulgaria Croatia Czech Republic Denmark Hungar...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_valid = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_valid.head()","metadata":{"id":"6ead45fb","outputId":"648a22cc-cb94-42dc-cd49-b87f51348476","execution":{"iopub.status.busy":"2022-02-07T08:14:40.719383Z","iopub.execute_input":"2022-02-07T08:14:40.719737Z","iopub.status.idle":"2022-02-07T08:14:41.276844Z","shell.execute_reply.started":"2022-02-07T08:14:40.719699Z","shell.execute_reply":"2022-02-07T08:14:41.275941Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   worker                                         less_toxic  \\\n0     313            This article sucks \\n\\nwoo woo wooooooo   \n1     188  \"And yes, people should recognize that but the...   \n2      82   Western Media?\\n\\nYup, because every crime in...   \n3     347  And you removed it! You numbskull! I don't car...   \n4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n\n                                          more_toxic  \n0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n2  \"Atom you don't believe actual photos of mastu...  \n3  You seem to have sand in your vagina.\\n\\nMight...  \n4           hey \\n\\nway to support nazis, you racist  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>worker</th>\n      <th>less_toxic</th>\n      <th>more_toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>313</td>\n      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>188</td>\n      <td>\"And yes, people should recognize that but the...</td>\n      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>82</td>\n      <td>Western Media?\\n\\nYup, because every crime in...</td>\n      <td>\"Atom you don't believe actual photos of mastu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>347</td>\n      <td>And you removed it! You numbskull! I don't car...</td>\n      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>539</td>\n      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n      <td>hey \\n\\nway to support nazis, you racist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text","metadata":{"id":"e9f7d35a","execution":{"iopub.status.busy":"2022-02-07T08:14:41.278302Z","iopub.execute_input":"2022-02-07T08:14:41.279032Z","iopub.status.idle":"2022-02-07T08:14:41.288191Z","shell.execute_reply.started":"2022-02-07T08:14:41.278983Z","shell.execute_reply":"2022-02-07T08:14:41.287205Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"'''df_train.less_toxic = df_train.less_toxic.apply(text_cleaning)\ndf_train.more_toxic = df_train.more_toxic.apply(text_cleaning)\ndf_valid.less_toxic = df_valid.less_toxic.apply(text_cleaning)\ndf_valid.more_toxic = df_valid.more_toxic.apply(text_cleaning)'''","metadata":{"id":"61cbfb69","outputId":"e21b98d9-6bd4-4047-b7d9-fb83b9b8988d","execution":{"iopub.status.busy":"2022-02-07T08:14:41.289444Z","iopub.execute_input":"2022-02-07T08:14:41.289760Z","iopub.status.idle":"2022-02-07T08:14:41.304969Z","shell.execute_reply.started":"2022-02-07T08:14:41.289728Z","shell.execute_reply":"2022-02-07T08:14:41.304294Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'df_train.less_toxic = df_train.less_toxic.apply(text_cleaning)\\ndf_train.more_toxic = df_train.more_toxic.apply(text_cleaning)\\ndf_valid.less_toxic = df_valid.less_toxic.apply(text_cleaning)\\ndf_valid.more_toxic = df_valid.more_toxic.apply(text_cleaning)'"},"metadata":{}}]},{"cell_type":"code","source":"df_train = df_train.sample(frac=1, random_state=CONFIG['seed'])\ndf_valid = df_valid.sample(frac=1, random_state=CONFIG['seed'])","metadata":{"id":"9ad97aca","execution":{"iopub.status.busy":"2022-02-07T08:14:41.306186Z","iopub.execute_input":"2022-02-07T08:14:41.306532Z","iopub.status.idle":"2022-02-07T08:14:41.336549Z","shell.execute_reply.started":"2022-02-07T08:14:41.306488Z","shell.execute_reply":"2022-02-07T08:14:41.335815Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.more_toxic = df['more_toxic'].values\n        self.less_toxic = df['less_toxic'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        more_toxic = self.more_toxic[index]\n        less_toxic = self.less_toxic[index]\n        inputs_more_toxic = self.tokenizer.encode_plus(\n                                more_toxic,\n                                truncation=True,\n                                add_special_tokens=True,\n                                max_length=self.max_len,\n                                padding='max_length'\n                            )\n        inputs_less_toxic = self.tokenizer.encode_plus(\n                                less_toxic,\n                                truncation=True,\n                                add_special_tokens=True,\n                                max_length=self.max_len,\n                                padding='max_length'\n                            )\n        target = 1\n        \n        more_toxic_ids = inputs_more_toxic['input_ids']\n        more_toxic_mask = inputs_more_toxic['attention_mask']\n        \n        less_toxic_ids = inputs_less_toxic['input_ids']\n        less_toxic_mask = inputs_less_toxic['attention_mask']\n        \n        \n        return {\n            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n            'target': torch.tensor(target, dtype=torch.long)\n        }\n","metadata":{"id":"7ba9ee6f","execution":{"iopub.status.busy":"2022-02-07T08:14:41.337916Z","iopub.execute_input":"2022-02-07T08:14:41.338288Z","iopub.status.idle":"2022-02-07T08:14:41.349379Z","shell.execute_reply.started":"2022-02-07T08:14:41.338258Z","shell.execute_reply":"2022-02-07T08:14:41.348192Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):\n        out = self.model(input_ids=ids,attention_mask=mask,\n                             output_hidden_states=False)\n        out = self.drop(out[1])\n        out = out[1]\n        outputs = self.fc(out)\n        \n        return outputs","metadata":{"id":"22d229d4","execution":{"iopub.status.busy":"2022-02-07T08:14:41.351038Z","iopub.execute_input":"2022-02-07T08:14:41.351925Z","iopub.status.idle":"2022-02-07T08:14:41.367035Z","shell.execute_reply.started":"2022-02-07T08:14:41.351877Z","shell.execute_reply":"2022-02-07T08:14:41.366008Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"JigsawM = xmp.MpModelWrapper(JigsawModel(CONFIG['model_name']))","metadata":{"id":"0MMYvC70Z1P4","outputId":"af7f5e0d-d033-40d7-f6e4-548fed7b0c2a","execution":{"iopub.status.busy":"2022-02-07T08:14:41.371703Z","iopub.execute_input":"2022-02-07T08:14:41.373928Z","iopub.status.idle":"2022-02-07T08:14:57.063147Z","shell.execute_reply.started":"2022-02-07T08:14:41.373876Z","shell.execute_reply":"2022-02-07T08:14:57.062131Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38b9570537424c76baa0c16c61e83b48"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at unitary/unbiased-toxic-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def criterion(outputs1, outputs2, targets):\n    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)","metadata":{"id":"ed4ff9d8","execution":{"iopub.status.busy":"2022-02-07T08:14:57.064721Z","iopub.execute_input":"2022-02-07T08:14:57.065056Z","iopub.status.idle":"2022-02-07T08:14:57.070620Z","shell.execute_reply.started":"2022-02-07T08:14:57.065013Z","shell.execute_reply":"2022-02-07T08:14:57.069144Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_more_toxic, y_less_toxic): \n    correct = torch.sum(torch.where(y_more_toxic>y_less_toxic, 1, 0))\n    wrong = torch.sum(torch.where(y_more_toxic<=y_less_toxic, 1, 0))\n    acc = correct / (correct + wrong)\n    return acc.view(-1).cpu().detach().numpy()","metadata":{"id":"2455f1ff","execution":{"iopub.status.busy":"2022-02-07T08:14:57.072199Z","iopub.execute_input":"2022-02-07T08:14:57.072916Z","iopub.status.idle":"2022-02-07T08:14:58.123166Z","shell.execute_reply.started":"2022-02-07T08:14:57.072875Z","shell.execute_reply":"2022-02-07T08:14:58.122161Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    score_batch = []\n\n    tk0 = tqdm(dataloader, total=len(dataloader), desc=\"Training\", disable=not xm.is_master_ordinal())\n    start_time = time.time()\n    \n    for bi, d in enumerate(tk0):\n            \n        \n        more_toxic_ids = d['more_toxic_ids'].to(device, dtype = torch.long)\n        more_toxic_mask = d['more_toxic_mask'].to(device, dtype = torch.long)\n        less_toxic_ids = d['less_toxic_ids'].to(device, dtype = torch.long)\n        less_toxic_mask = d['less_toxic_mask'].to(device, dtype = torch.long)\n        targets = d['target'].to(device, dtype=torch.long)\n\n        batch_size = more_toxic_ids.size(0)\n\n        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n        loss = loss / CONFIG['n_accumulate']\n            \n        score_batch.append(accuracy(more_toxic_outputs, less_toxic_outputs))\n        \n        loss.backward()\n\n        if (bi + 1) % CONFIG['n_accumulate'] == 0:\n\n            xm.optimizer_step(optimizer)    \n            #optimizer.step()\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            if scheduler is not None:\n                scheduler.step()\n        # since the loss is on all 8 cores, reduce the loss values and print the average\n        loss_reduced = xm.mesh_reduce('loss_reduce',loss, lambda x: sum(x) / len(x)) \n\n        if bi % 100 == 0:\n            xm.master_print(\n                f\"bi={bi}, {time.time()-start_time:<2.2f} - loss:{loss_reduced}\"\n            )\n \n        running_loss += (loss_reduced.detach().item() * batch_size)\n        dataset_size += batch_size\n\n        epoch_loss = running_loss / dataset_size\n        \n        epoch_score = np.mean(score_batch)\n\n        tk0.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                            LR=optimizer.param_groups[0]['lr'])\n\n    del loss\n    del running_loss\n    del loss_reduced\n    gc.collect()\n    return epoch_loss, epoch_score\n","metadata":{"id":"e8a4e199","execution":{"iopub.status.busy":"2022-02-07T08:14:58.124736Z","iopub.execute_input":"2022-02-07T08:14:58.125111Z","iopub.status.idle":"2022-02-07T08:14:58.144932Z","shell.execute_reply.started":"2022-02-07T08:14:58.125015Z","shell.execute_reply":"2022-02-07T08:14:58.144093Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    score_batch = []\n\n    vk0 = tqdm(dataloader, total=len(dataloader), desc=\"Validation\", disable=not xm.is_master_ordinal())\n    \n    for bi, d in enumerate(vk0):        \n        more_toxic_ids = d['more_toxic_ids'].to(device, dtype = torch.long)\n        more_toxic_mask = d['more_toxic_mask'].to(device, dtype = torch.long)\n        less_toxic_ids = d['less_toxic_ids'].to(device, dtype = torch.long)\n        less_toxic_mask = d['less_toxic_mask'].to(device, dtype = torch.long)\n        targets = d['target'].to(device, dtype=torch.long)\n        \n        batch_size = more_toxic_ids.size(0)\n\n        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask)\n        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask)\n        \n        loss = criterion(more_toxic_outputs, less_toxic_outputs, targets)\n        score_batch.append(accuracy(more_toxic_outputs, less_toxic_outputs))\n\n        # since the loss is on all 8 cores, reduce the loss values and print the average\n        loss_reduced = xm.mesh_reduce('loss_reduce',loss, lambda x: sum(x) / len(x)) \n        # master_print will only print once (not from all 8 cores)\n        #xm.master_print(f'val. loss={loss_reduced}')\n        \n        running_loss += (loss_reduced.detach().item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        epoch_score = np.mean(score_batch)\n        \n        vk0.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)   \n    \n    gc.collect()\n    return epoch_loss, epoch_score\n","metadata":{"id":"febba625","execution":{"iopub.status.busy":"2022-02-07T08:14:58.146603Z","iopub.execute_input":"2022-02-07T08:14:58.146879Z","iopub.status.idle":"2022-02-07T08:14:58.165313Z","shell.execute_reply.started":"2022-02-07T08:14:58.146840Z","shell.execute_reply":"2022-02-07T08:14:58.164365Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"id":"ITFZOpil2VhP","execution":{"iopub.status.busy":"2022-02-07T08:14:58.166764Z","iopub.execute_input":"2022-02-07T08:14:58.167363Z","iopub.status.idle":"2022-02-07T08:14:58.183847Z","shell.execute_reply.started":"2022-02-07T08:14:58.167323Z","shell.execute_reply":"2022-02-07T08:14:58.182852Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def run(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    \n    device = xm.xla_device() # our device (single TPU core)\n    \n    xm.set_rng_state(CONFIG['seed'], device)\n    fold = FLAGS[\"fold\"]\n\n   \n    \n    \n    train_dataset = JigsawDataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n    valid_dataset = JigsawDataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n\n    \n    # special sampler needed for distributed/multi-core (divides dataset among the replicas/cores/devices)\n    train_sampler = torch.utils.data.distributed.DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(), #divide dataset among this many replicas\n        rank=xm.get_ordinal(), #which replica/device/core\n        shuffle=True)\n    \n    # define DataLoader with the defined sampler\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=CONFIG['train_batch_size'],\n        sampler=train_sampler,\n        num_workers=0,\n        drop_last=True)\n    \n    # same as train but with valid data\n    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False)\n\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size=CONFIG['valid_batch_size'],\n        sampler=valid_sampler,\n        num_workers=0,\n        drop_last=False)\n    \n    \n    train_loader = pl.MpDeviceLoader(train_loader, device) # puts the train data onto the current TPU core\n    valid_loader = pl.MpDeviceLoader(valid_loader, device) # puts the valid data onto the current TPU core\n    \n\n    model = JigsawM.to(device) # put model onto the current TPU core\n\n    lr = CONFIG['learning_rate'] * xm.xrt_world_size()\n    optimizer = AdamW(model.parameters(), lr=lr, eps=CONFIG['epsilon'], weight_decay=CONFIG['weight_decay'])\n    scheduler = fetch_scheduler(optimizer)\n\n    gc.collect()\n\n    best_epoch_loss = np.inf\n    history = defaultdict(list)\n    epochs_no_improve = 0\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    \n    xm.master_print(f'========== training fold {FLAGS[\"fold\"]} for {CONFIG[\"epochs\"]} epochs ==========')\n    for epoch in range(CONFIG[\"epochs\"]):\n        xm.master_print(f'EPOCH {i}:')\n        # train one epoch\n        train_epoch_loss, train_epoch_score = train_one_epoch(model, optimizer, scheduler,\n                                                              train_loader, device, epoch)\n                \n        # validation one epoch\n        val_epoch_loss, val_epoch_score = valid_one_epoch(model, valid_loader, device, epoch)\n\n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Train Score'].append(train_epoch_score)\n        history['Valid Score'].append(val_epoch_score)\n        \n        xm.master_print(f\"Train score {train_epoch_score}\")\n        xm.master_print(f\"Valid score {val_epoch_score}\")\n\n        if val_epoch_loss <= best_epoch_loss:\n            xm.master_print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n            best_epoch_loss = val_epoch_loss\n            history[\"Best Loss\"].append(best_epoch_loss)\n            best_model_wts = copy.deepcopy(model.state_dict())\n            xm.rendezvous('save_model')\n    \n            xm.master_print('save model')\n\n            PATH =f'Loss-Fold-{FLAGS[\"fold\"]}.bin'\n    \n            xm.save(model.state_dict(), PATH)\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= CONFIG[\"patience\"]:\n                xm.master_print('Early stopping!' )\n                xm.master_print()\n                break\n\n        model.load_state_dict(best_model_wts)\n\n        gc.collect()\n    \n    ","metadata":{"id":"ht1xjCwlyT7l","execution":{"iopub.status.busy":"2022-02-07T08:14:58.185567Z","iopub.execute_input":"2022-02-07T08:14:58.186101Z","iopub.status.idle":"2022-02-07T08:14:58.207954Z","shell.execute_reply.started":"2022-02-07T08:14:58.186065Z","shell.execute_reply":"2022-02-07T08:14:58.206958Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for i in range(CONFIG['n_fold']):\n    FLAGS={}\n    FLAGS[\"fold\"] = i\n    start_time = time.time()\n    xmp.spawn(run, args=(FLAGS,), nprocs=8, start_method='fork')\n    print('time taken: ', time.time()-start_time)\n    print('==============================================================================')\n\n","metadata":{"id":"dxkUiPx1ZZJo","outputId":"89981816-e2a8-4c3f-9725-ac35413a5620","execution":{"iopub.status.busy":"2022-02-07T08:14:58.209307Z","iopub.execute_input":"2022-02-07T08:14:58.209776Z","iopub.status.idle":"2022-02-07T09:28:54.340865Z","shell.execute_reply.started":"2022-02-07T08:14:58.209740Z","shell.execute_reply":"2022-02-07T09:28:54.339671Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"========== training fold 0 for 10 epochs ==========\nEPOCH 0:\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/939 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"bi=0, 22.42 - loss:0.38427734375\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 100/939 [03:49<11:18,  1.24it/s, Epoch=0, LR=7.25e-5, Train_Loss=0.429]","output_type":"stream"},{"name":"stdout","text":"bi=100, 230.27 - loss:0.233154296875\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██▏       | 200/939 [05:10<10:06,  1.22it/s, Epoch=0, LR=5.27e-5, Train_Loss=0.416]","output_type":"stream"},{"name":"stdout","text":"bi=200, 311.00 - loss:0.233642578125\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 300/939 [06:31<08:31,  1.25it/s, Epoch=0, LR=2.83e-5, Train_Loss=0.412]","output_type":"stream"},{"name":"stdout","text":"bi=300, 391.95 - loss:0.5029296875\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 400/939 [07:56<08:30,  1.06it/s, Epoch=0, LR=8.54e-6, Train_Loss=0.409]","output_type":"stream"},{"name":"stdout","text":"bi=400, 477.27 - loss:0.2841796875\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 500/939 [09:17<05:45,  1.27it/s, Epoch=0, LR=1e-6, Train_Loss=0.405]   ","output_type":"stream"},{"name":"stdout","text":"bi=500, 558.05 - loss:0.3701171875\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 600/939 [10:38<04:40,  1.21it/s, Epoch=0, LR=8.54e-6, Train_Loss=0.4]  ","output_type":"stream"},{"name":"stdout","text":"bi=600, 639.22 - loss:0.70166015625\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▍  | 700/939 [11:59<03:15,  1.22it/s, Epoch=0, LR=2.83e-5, Train_Loss=0.396]","output_type":"stream"},{"name":"stdout","text":"bi=700, 720.73 - loss:0.37744140625\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 800/939 [13:21<01:54,  1.21it/s, Epoch=0, LR=5.27e-5, Train_Loss=0.394]","output_type":"stream"},{"name":"stdout","text":"bi=800, 802.05 - loss:0.191162109375\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 900/939 [14:42<00:31,  1.23it/s, Epoch=0, LR=7.25e-5, Train_Loss=0.394]","output_type":"stream"},{"name":"stdout","text":"bi=900, 883.04 - loss:0.548095703125\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 939/939 [15:13<00:00,  1.03it/s, Epoch=0, LR=7.71e-5, Train_Loss=0.394]\nValidation: 100%|██████████| 236/236 [02:21<00:00,  1.66it/s, Epoch=0, Valid_Loss=0.368]\n","output_type":"stream"},{"name":"stdout","text":"Train score 0.6485623121261597\nValid score 0.7118644118309021\nValidation Loss Improved (inf ---> 0.3682491614638682)\nsave model\nEPOCH 0:\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/939 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"bi=0, 0.95 - loss:0.3720703125\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 100/939 [01:19<10:59,  1.27it/s, Epoch=1, LR=7.88e-5, Train_Loss=0.292]","output_type":"stream"},{"name":"stdout","text":"bi=100, 80.18 - loss:0.102783203125\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██▏       | 200/939 [02:38<09:45,  1.26it/s, Epoch=1, LR=6.59e-5, Train_Loss=0.316]","output_type":"stream"},{"name":"stdout","text":"bi=200, 159.57 - loss:0.15234375\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 300/939 [03:57<08:14,  1.29it/s, Epoch=1, LR=4.32e-5, Train_Loss=0.329]","output_type":"stream"},{"name":"stdout","text":"bi=300, 238.65 - loss:0.8603515625\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 400/939 [05:17<07:03,  1.27it/s, Epoch=1, LR=1.95e-5, Train_Loss=0.336]","output_type":"stream"},{"name":"stdout","text":"bi=400, 318.27 - loss:0.507080078125\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 500/939 [06:36<05:47,  1.26it/s, Epoch=1, LR=3.87e-6, Train_Loss=0.343]","output_type":"stream"},{"name":"stdout","text":"bi=500, 397.32 - loss:0.501708984375\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 600/939 [07:56<04:32,  1.24it/s, Epoch=1, LR=2.18e-6, Train_Loss=0.347]","output_type":"stream"},{"name":"stdout","text":"bi=600, 477.15 - loss:0.465576171875\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▍  | 700/939 [09:16<03:11,  1.25it/s, Epoch=1, LR=1.51e-5, Train_Loss=0.35] ","output_type":"stream"},{"name":"stdout","text":"bi=700, 556.96 - loss:0.2275390625\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 800/939 [10:35<01:48,  1.28it/s, Epoch=1, LR=3.78e-5, Train_Loss=0.349]","output_type":"stream"},{"name":"stdout","text":"bi=800, 636.66 - loss:0.20947265625\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 900/939 [11:56<00:31,  1.25it/s, Epoch=1, LR=6.15e-5, Train_Loss=0.34] ","output_type":"stream"},{"name":"stdout","text":"bi=900, 717.11 - loss:0.17041015625\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 939/939 [12:27<00:00,  1.26it/s, Epoch=1, LR=6.9e-5, Train_Loss=0.337] \nValidation: 100%|██████████| 236/236 [01:33<00:00,  2.53it/s, Epoch=1, Valid_Loss=0.505]\n","output_type":"stream"},{"name":"stdout","text":"Train score 0.7060703039169312\nValid score 0.694915235042572\nEPOCH 0:\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/939 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"bi=0, 0.71 - loss:0.193359375\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 100/939 [01:18<10:54,  1.28it/s, Epoch=2, LR=7.96e-5, Train_Loss=0.317]","output_type":"stream"},{"name":"stdout","text":"bi=100, 79.02 - loss:0.302734375\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██▏       | 200/939 [02:37<09:42,  1.27it/s, Epoch=2, LR=7.54e-5, Train_Loss=0.33] ","output_type":"stream"},{"name":"stdout","text":"bi=200, 158.41 - loss:0.413330078125\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 300/939 [03:57<08:15,  1.29it/s, Epoch=2, LR=5.78e-5, Train_Loss=0.338]","output_type":"stream"},{"name":"stdout","text":"bi=300, 238.00 - loss:0.382568359375\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 400/939 [05:16<07:01,  1.28it/s, Epoch=2, LR=3.36e-5, Train_Loss=0.349]","output_type":"stream"},{"name":"stdout","text":"bi=400, 316.86 - loss:0.510009765625\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 500/939 [06:35<05:38,  1.30it/s, Epoch=2, LR=1.2e-5, Train_Loss=0.353] ","output_type":"stream"},{"name":"stdout","text":"bi=500, 396.00 - loss:0.23095703125\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 600/939 [07:54<04:28,  1.26it/s, Epoch=2, LR=1.38e-6, Train_Loss=0.351]","output_type":"stream"},{"name":"stdout","text":"bi=600, 475.26 - loss:0.906982421875\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▍  | 700/939 [09:13<03:11,  1.25it/s, Epoch=2, LR=5.65e-6, Train_Loss=0.349]","output_type":"stream"},{"name":"stdout","text":"bi=700, 554.42 - loss:0.35107421875\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 800/939 [10:33<01:51,  1.24it/s, Epoch=2, LR=2.32e-5, Train_Loss=0.349]","output_type":"stream"},{"name":"stdout","text":"bi=800, 633.92 - loss:0.142822265625\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 900/939 [11:52<00:31,  1.25it/s, Epoch=2, LR=4.74e-5, Train_Loss=0.342]","output_type":"stream"},{"name":"stdout","text":"bi=900, 712.91 - loss:0.29296875\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 939/939 [12:23<00:00,  1.26it/s, Epoch=2, LR=5.66e-5, Train_Loss=0.339]\nValidation: 100%|██████████| 236/236 [01:33<00:00,  2.53it/s, Epoch=2, Valid_Loss=0.444]\n","output_type":"stream"},{"name":"stdout","text":"Train score 0.7113950848579407\nValid score 0.6991525292396545\nEPOCH 0:\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/939 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"bi=0, 0.71 - loss:0.268798828125\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 100/939 [01:18<11:10,  1.25it/s, Epoch=3, LR=7.47e-5, Train_Loss=0.291]","output_type":"stream"},{"name":"stdout","text":"bi=100, 79.54 - loss:0.299560546875\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██▏       | 200/939 [02:37<09:34,  1.29it/s, Epoch=3, LR=7.98e-5, Train_Loss=0.296]","output_type":"stream"},{"name":"stdout","text":"bi=200, 157.94 - loss:0.28955078125\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 300/939 [03:56<08:32,  1.25it/s, Epoch=3, LR=6.98e-5, Train_Loss=0.31] ","output_type":"stream"},{"name":"stdout","text":"bi=300, 237.36 - loss:0.7275390625\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 400/939 [05:15<06:57,  1.29it/s, Epoch=3, LR=4.86e-5, Train_Loss=0.333]","output_type":"stream"},{"name":"stdout","text":"bi=400, 316.64 - loss:0.355224609375\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 500/939 [06:35<05:50,  1.25it/s, Epoch=3, LR=2.44e-5, Train_Loss=0.341]","output_type":"stream"},{"name":"stdout","text":"bi=500, 395.79 - loss:0.255859375\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 600/939 [07:54<04:30,  1.25it/s, Epoch=3, LR=6.25e-6, Train_Loss=0.344]","output_type":"stream"},{"name":"stdout","text":"bi=600, 475.39 - loss:0.524658203125\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▍  | 700/939 [09:13<03:11,  1.25it/s, Epoch=3, LR=1.23e-6, Train_Loss=0.347]","output_type":"stream"},{"name":"stdout","text":"bi=700, 554.64 - loss:0.27001953125\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 800/939 [10:33<01:49,  1.27it/s, Epoch=3, LR=1.12e-5, Train_Loss=0.343]","output_type":"stream"},{"name":"stdout","text":"bi=800, 634.07 - loss:0.030029296875\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 900/939 [11:52<00:30,  1.27it/s, Epoch=3, LR=3.24e-5, Train_Loss=0.335]","output_type":"stream"},{"name":"stdout","text":"bi=900, 713.59 - loss:0.17333984375\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 939/939 [12:24<00:00,  1.26it/s, Epoch=3, LR=4.2e-5, Train_Loss=0.334] \nValidation: 100%|██████████| 236/236 [01:33<00:00,  2.51it/s, Epoch=3, Valid_Loss=0.449]\n","output_type":"stream"},{"name":"stdout","text":"Train score 0.7188498377799988\nValid score 0.7203390002250671\nEPOCH 0:\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/939 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"bi=0, 0.74 - loss:0.380126953125\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 100/939 [01:18<11:17,  1.24it/s, Epoch=4, LR=6.49e-5, Train_Loss=0.288]","output_type":"stream"},{"name":"stdout","text":"bi=100, 79.73 - loss:0.34814453125\n","output_type":"stream"},{"name":"stderr","text":"Training:  21%|██▏       | 200/939 [02:38<09:42,  1.27it/s, Epoch=4, LR=7.85e-5, Train_Loss=0.272]","output_type":"stream"},{"name":"stdout","text":"bi=200, 158.79 - loss:0.251220703125\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|███▏      | 300/939 [03:57<08:23,  1.27it/s, Epoch=4, LR=7.76e-5, Train_Loss=0.293]","output_type":"stream"},{"name":"stdout","text":"bi=300, 237.87 - loss:0.92626953125\n","output_type":"stream"},{"name":"stderr","text":"Training:  43%|████▎     | 400/939 [05:16<07:04,  1.27it/s, Epoch=4, LR=6.25e-5, Train_Loss=0.317]","output_type":"stream"},{"name":"stdout","text":"bi=400, 316.90 - loss:0.275390625\n","output_type":"stream"},{"name":"stderr","text":"Training:  53%|█████▎    | 500/939 [06:35<05:46,  1.27it/s, Epoch=4, LR=3.9e-5, Train_Loss=0.323] ","output_type":"stream"},{"name":"stdout","text":"bi=500, 396.69 - loss:0.693359375\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████▍   | 600/939 [07:55<04:31,  1.25it/s, Epoch=4, LR=1.61e-5, Train_Loss=0.331]","output_type":"stream"},{"name":"stdout","text":"bi=600, 476.17 - loss:0.617431640625\n","output_type":"stream"},{"name":"stderr","text":"Training:  75%|███████▍  | 700/939 [09:14<03:13,  1.23it/s, Epoch=4, LR=2.5e-6, Train_Loss=0.331] ","output_type":"stream"},{"name":"stdout","text":"bi=700, 555.71 - loss:0.2724609375\n","output_type":"stream"},{"name":"stderr","text":"Training:  85%|████████▌ | 800/939 [10:35<01:51,  1.24it/s, Epoch=4, LR=3.42e-6, Train_Loss=0.329]","output_type":"stream"},{"name":"stdout","text":"bi=800, 635.91 - loss:0.182373046875\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████▌| 900/939 [11:54<00:31,  1.23it/s, Epoch=4, LR=1.85e-5, Train_Loss=0.322]","output_type":"stream"},{"name":"stdout","text":"bi=900, 715.20 - loss:0.209228515625\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 939/939 [12:25<00:00,  1.26it/s, Epoch=4, LR=2.71e-5, Train_Loss=0.32] \nValidation: 100%|██████████| 236/236 [01:32<00:00,  2.54it/s, Epoch=4, Valid_Loss=0.408]\n","output_type":"stream"},{"name":"stdout","text":"Train score 0.7358892560005188\nValid score 0.7033898234367371\nEarly stopping!\n\ntime taken:  4436.113703012466\n==============================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"f5e26a83"},"execution_count":null,"outputs":[]}]}